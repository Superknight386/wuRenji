[ Wed Oct 16 23:41:55 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:41:55 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 24, 'test_batch_size': 24, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:41:55 2024 ] Training epoch: 1
[ Wed Oct 16 23:44:28 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:44:28 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 24, 'test_batch_size': 24, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:44:28 2024 ] Training epoch: 1
[ Wed Oct 16 23:45:47 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:45:47 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 1, 'test_batch_size': 1, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:45:47 2024 ] Training epoch: 1
[ Wed Oct 16 23:47:52 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:47:52 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 1, 'test_batch_size': 1, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:47:52 2024 ] Training epoch: 1
[ Wed Oct 16 23:48:12 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:48:12 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 24, 'test_batch_size': 24, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:48:12 2024 ] Training epoch: 1
[ Wed Oct 16 23:48:24 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:48:24 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 56, 'test_batch_size': 56, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:48:24 2024 ] Training epoch: 1
[ Wed Oct 16 23:48:38 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:48:38 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 128, 'test_batch_size': 128, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:48:38 2024 ] Training epoch: 1
[ Wed Oct 16 23:49:14 2024 ] using warm up, epoch: 5
[ Wed Oct 16 23:49:14 2024 ] Parameters:
{'work_dir': 'work_dir/msst', 'model_saved_name': 'runs/msst', 'config': './config/train_msst.yaml', 'phase': 'train', 'save_score': True, 'seed': 777, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_gcl.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': -1, 'normalization': False}, 'test_feeder_args': {'data_path': './data/test_joint.npy', 'label_path': './data/test_label.npy'}, 'model': 'model.msst.Model', 'model_args': {'num_class': 155, 'dropout': 0.8}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.1, 'step': [30, 40], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 184, 'test_batch_size': 184, 'start_epoch': 0, 'num_epoch': 50, 'weight_decay': 0.0001, 'only_train_part': False, 'only_train_epoch': 60, 'warm_up_epoch': 5}

[ Wed Oct 16 23:49:14 2024 ] Training epoch: 1
[ Wed Oct 16 23:50:01 2024 ] 	ACC:0.0109.
[ Wed Oct 16 23:50:01 2024 ] 	Mean training loss: 4.8643.
[ Wed Oct 16 23:50:01 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Oct 16 23:50:01 2024 ] Eval epoch: 1
[ Wed Oct 16 23:50:06 2024 ] Training epoch: 2
[ Wed Oct 16 23:50:54 2024 ] 	ACC:0.0380.
[ Wed Oct 16 23:50:54 2024 ] 	Mean training loss: 4.4107.
[ Wed Oct 16 23:50:54 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Oct 16 23:50:54 2024 ] Eval epoch: 2
[ Wed Oct 16 23:50:59 2024 ] Training epoch: 3
[ Wed Oct 16 23:51:46 2024 ] 	ACC:0.0815.
[ Wed Oct 16 23:51:46 2024 ] 	Mean training loss: 3.9815.
[ Wed Oct 16 23:51:46 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Oct 16 23:51:46 2024 ] Eval epoch: 3
[ Wed Oct 16 23:51:52 2024 ] Training epoch: 4
[ Wed Oct 16 23:52:39 2024 ] 	ACC:0.1413.
[ Wed Oct 16 23:52:39 2024 ] 	Mean training loss: 3.6292.
[ Wed Oct 16 23:52:39 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Oct 16 23:52:39 2024 ] Eval epoch: 4
[ Wed Oct 16 23:52:44 2024 ] Training epoch: 5
[ Wed Oct 16 23:53:32 2024 ] 	ACC:0.2011.
[ Wed Oct 16 23:53:32 2024 ] 	Mean training loss: 3.3582.
[ Wed Oct 16 23:53:32 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Oct 16 23:53:32 2024 ] Eval epoch: 5
[ Wed Oct 16 23:53:37 2024 ] Training epoch: 6
[ Wed Oct 16 23:54:24 2024 ] 	ACC:0.2717.
[ Wed Oct 16 23:54:24 2024 ] 	Mean training loss: 3.1136.
[ Wed Oct 16 23:54:24 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Oct 16 23:54:24 2024 ] Eval epoch: 6
[ Wed Oct 16 23:54:29 2024 ] Training epoch: 7
[ Wed Oct 16 23:55:17 2024 ] 	ACC:0.2717.
[ Wed Oct 16 23:55:17 2024 ] 	Mean training loss: 2.9243.
[ Wed Oct 16 23:55:17 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Oct 16 23:55:17 2024 ] Eval epoch: 7
[ Wed Oct 16 23:55:22 2024 ] Training epoch: 8
[ Wed Oct 16 23:56:09 2024 ] 	ACC:0.2391.
[ Wed Oct 16 23:56:09 2024 ] 	Mean training loss: 2.7489.
[ Wed Oct 16 23:56:09 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Oct 16 23:56:10 2024 ] Eval epoch: 8
[ Wed Oct 16 23:56:15 2024 ] Training epoch: 9
[ Wed Oct 16 23:57:02 2024 ] 	ACC:0.2174.
[ Wed Oct 16 23:57:02 2024 ] 	Mean training loss: 2.6251.
[ Wed Oct 16 23:57:02 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Oct 16 23:57:02 2024 ] Eval epoch: 9
[ Wed Oct 16 23:57:07 2024 ] Training epoch: 10
[ Wed Oct 16 23:57:55 2024 ] 	ACC:0.2554.
[ Wed Oct 16 23:57:55 2024 ] 	Mean training loss: 2.4941.
[ Wed Oct 16 23:57:55 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Oct 16 23:57:55 2024 ] Eval epoch: 10
[ Wed Oct 16 23:58:00 2024 ] Training epoch: 11
[ Wed Oct 16 23:58:47 2024 ] 	ACC:0.3804.
[ Wed Oct 16 23:58:47 2024 ] 	Mean training loss: 2.3819.
[ Wed Oct 16 23:58:47 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Oct 16 23:58:47 2024 ] Eval epoch: 11
[ Wed Oct 16 23:58:52 2024 ] Training epoch: 12
[ Wed Oct 16 23:59:40 2024 ] 	ACC:0.4130.
[ Wed Oct 16 23:59:40 2024 ] 	Mean training loss: 2.2835.
[ Wed Oct 16 23:59:40 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Oct 16 23:59:40 2024 ] Eval epoch: 12
[ Wed Oct 16 23:59:45 2024 ] Training epoch: 13
[ Thu Oct 17 00:00:32 2024 ] 	ACC:0.4022.
[ Thu Oct 17 00:00:32 2024 ] 	Mean training loss: 2.1834.
[ Thu Oct 17 00:00:32 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:00:32 2024 ] Eval epoch: 13
[ Thu Oct 17 00:00:38 2024 ] Training epoch: 14
[ Thu Oct 17 00:01:25 2024 ] 	ACC:0.4620.
[ Thu Oct 17 00:01:25 2024 ] 	Mean training loss: 2.0907.
[ Thu Oct 17 00:01:25 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:01:25 2024 ] Eval epoch: 14
[ Thu Oct 17 00:01:30 2024 ] Training epoch: 15
[ Thu Oct 17 00:02:18 2024 ] 	ACC:0.3913.
[ Thu Oct 17 00:02:18 2024 ] 	Mean training loss: 2.0252.
[ Thu Oct 17 00:02:18 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:02:18 2024 ] Eval epoch: 15
[ Thu Oct 17 00:02:23 2024 ] Training epoch: 16
[ Thu Oct 17 00:03:10 2024 ] 	ACC:0.4674.
[ Thu Oct 17 00:03:10 2024 ] 	Mean training loss: 1.9348.
[ Thu Oct 17 00:03:10 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:03:10 2024 ] Eval epoch: 16
[ Thu Oct 17 00:03:15 2024 ] Training epoch: 17
[ Thu Oct 17 00:04:03 2024 ] 	ACC:0.4565.
[ Thu Oct 17 00:04:03 2024 ] 	Mean training loss: 1.8568.
[ Thu Oct 17 00:04:03 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:04:03 2024 ] Eval epoch: 17
[ Thu Oct 17 00:04:08 2024 ] Training epoch: 18
[ Thu Oct 17 00:04:55 2024 ] 	ACC:0.5217.
[ Thu Oct 17 00:04:55 2024 ] 	Mean training loss: 1.7968.
[ Thu Oct 17 00:04:55 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:04:55 2024 ] Eval epoch: 18
[ Thu Oct 17 00:05:00 2024 ] Training epoch: 19
[ Thu Oct 17 00:05:48 2024 ] 	ACC:0.4674.
[ Thu Oct 17 00:05:48 2024 ] 	Mean training loss: 1.7193.
[ Thu Oct 17 00:05:48 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:05:48 2024 ] Eval epoch: 19
[ Thu Oct 17 00:05:53 2024 ] Training epoch: 20
[ Thu Oct 17 00:06:40 2024 ] 	ACC:0.5163.
[ Thu Oct 17 00:06:40 2024 ] 	Mean training loss: 1.6679.
[ Thu Oct 17 00:06:40 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:06:40 2024 ] Eval epoch: 20
[ Thu Oct 17 00:06:45 2024 ] Training epoch: 21
[ Thu Oct 17 00:07:33 2024 ] 	ACC:0.5707.
[ Thu Oct 17 00:07:33 2024 ] 	Mean training loss: 1.5787.
[ Thu Oct 17 00:07:33 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:07:33 2024 ] Eval epoch: 21
[ Thu Oct 17 00:07:38 2024 ] Training epoch: 22
[ Thu Oct 17 00:08:25 2024 ] 	ACC:0.5380.
[ Thu Oct 17 00:08:25 2024 ] 	Mean training loss: 1.5262.
[ Thu Oct 17 00:08:25 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:08:25 2024 ] Eval epoch: 22
[ Thu Oct 17 00:08:30 2024 ] Training epoch: 23
[ Thu Oct 17 00:09:18 2024 ] 	ACC:0.5870.
[ Thu Oct 17 00:09:18 2024 ] 	Mean training loss: 1.4711.
[ Thu Oct 17 00:09:18 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:09:18 2024 ] Eval epoch: 23
[ Thu Oct 17 00:09:23 2024 ] Training epoch: 24
[ Thu Oct 17 00:10:10 2024 ] 	ACC:0.5435.
[ Thu Oct 17 00:10:10 2024 ] 	Mean training loss: 1.4073.
[ Thu Oct 17 00:10:10 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:10:10 2024 ] Eval epoch: 24
[ Thu Oct 17 00:10:15 2024 ] Training epoch: 25
[ Thu Oct 17 00:11:03 2024 ] 	ACC:0.5815.
[ Thu Oct 17 00:11:03 2024 ] 	Mean training loss: 1.3427.
[ Thu Oct 17 00:11:03 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:11:03 2024 ] Eval epoch: 25
[ Thu Oct 17 00:11:08 2024 ] Training epoch: 26
[ Thu Oct 17 00:11:55 2024 ] 	ACC:0.5489.
[ Thu Oct 17 00:11:55 2024 ] 	Mean training loss: 1.3015.
[ Thu Oct 17 00:11:55 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:11:55 2024 ] Eval epoch: 26
[ Thu Oct 17 00:12:00 2024 ] Training epoch: 27
[ Thu Oct 17 00:12:48 2024 ] 	ACC:0.6467.
[ Thu Oct 17 00:12:48 2024 ] 	Mean training loss: 1.2391.
[ Thu Oct 17 00:12:48 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:12:48 2024 ] Eval epoch: 27
[ Thu Oct 17 00:12:53 2024 ] Training epoch: 28
[ Thu Oct 17 00:13:40 2024 ] 	ACC:0.6576.
[ Thu Oct 17 00:13:40 2024 ] 	Mean training loss: 1.1685.
[ Thu Oct 17 00:13:40 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:13:40 2024 ] Eval epoch: 28
[ Thu Oct 17 00:13:45 2024 ] Training epoch: 29
[ Thu Oct 17 00:14:33 2024 ] 	ACC:0.6576.
[ Thu Oct 17 00:14:33 2024 ] 	Mean training loss: 1.1120.
[ Thu Oct 17 00:14:33 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:14:33 2024 ] Eval epoch: 29
[ Thu Oct 17 00:14:38 2024 ] Training epoch: 30
[ Thu Oct 17 00:15:25 2024 ] 	ACC:0.7228.
[ Thu Oct 17 00:15:25 2024 ] 	Mean training loss: 1.0506.
[ Thu Oct 17 00:15:25 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:15:25 2024 ] Eval epoch: 30
[ Thu Oct 17 00:15:30 2024 ] Training epoch: 31
[ Thu Oct 17 00:16:18 2024 ] 	ACC:0.7935.
[ Thu Oct 17 00:16:18 2024 ] 	Mean training loss: 0.7018.
[ Thu Oct 17 00:16:18 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:16:18 2024 ] Eval epoch: 31
[ Thu Oct 17 00:16:23 2024 ] Training epoch: 32
[ Thu Oct 17 00:17:10 2024 ] 	ACC:0.8207.
[ Thu Oct 17 00:17:10 2024 ] 	Mean training loss: 0.5384.
[ Thu Oct 17 00:17:10 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:17:11 2024 ] Eval epoch: 32
[ Thu Oct 17 00:17:16 2024 ] Training epoch: 33
[ Thu Oct 17 00:18:03 2024 ] 	ACC:0.8859.
[ Thu Oct 17 00:18:03 2024 ] 	Mean training loss: 0.4641.
[ Thu Oct 17 00:18:03 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:18:03 2024 ] Eval epoch: 33
[ Thu Oct 17 00:18:08 2024 ] Training epoch: 34
[ Thu Oct 17 00:18:55 2024 ] 	ACC:0.8533.
[ Thu Oct 17 00:18:55 2024 ] 	Mean training loss: 0.4129.
[ Thu Oct 17 00:18:55 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:18:56 2024 ] Eval epoch: 34
[ Thu Oct 17 00:19:01 2024 ] Training epoch: 35
[ Thu Oct 17 00:19:48 2024 ] 	ACC:0.8913.
[ Thu Oct 17 00:19:48 2024 ] 	Mean training loss: 0.3692.
[ Thu Oct 17 00:19:48 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:19:48 2024 ] Eval epoch: 35
[ Thu Oct 17 00:19:53 2024 ] Training epoch: 36
[ Thu Oct 17 00:20:40 2024 ] 	ACC:0.8967.
[ Thu Oct 17 00:20:40 2024 ] 	Mean training loss: 0.3376.
[ Thu Oct 17 00:20:40 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:20:41 2024 ] Eval epoch: 36
[ Thu Oct 17 00:20:45 2024 ] Training epoch: 37
[ Thu Oct 17 00:21:33 2024 ] 	ACC:0.9130.
[ Thu Oct 17 00:21:33 2024 ] 	Mean training loss: 0.3075.
[ Thu Oct 17 00:21:33 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:21:33 2024 ] Eval epoch: 37
[ Thu Oct 17 00:21:38 2024 ] Training epoch: 38
[ Thu Oct 17 00:22:26 2024 ] 	ACC:0.8859.
[ Thu Oct 17 00:22:26 2024 ] 	Mean training loss: 0.2803.
[ Thu Oct 17 00:22:26 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:22:26 2024 ] Eval epoch: 38
[ Thu Oct 17 00:22:31 2024 ] Training epoch: 39
[ Thu Oct 17 00:23:18 2024 ] 	ACC:0.8859.
[ Thu Oct 17 00:23:18 2024 ] 	Mean training loss: 0.2592.
[ Thu Oct 17 00:23:18 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:23:18 2024 ] Eval epoch: 39
[ Thu Oct 17 00:23:23 2024 ] Training epoch: 40
[ Thu Oct 17 00:24:11 2024 ] 	ACC:0.9457.
[ Thu Oct 17 00:24:11 2024 ] 	Mean training loss: 0.2374.
[ Thu Oct 17 00:24:11 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:24:11 2024 ] Eval epoch: 40
[ Thu Oct 17 00:24:16 2024 ] Training epoch: 41
[ Thu Oct 17 00:25:03 2024 ] 	ACC:0.9402.
[ Thu Oct 17 00:25:03 2024 ] 	Mean training loss: 0.2078.
[ Thu Oct 17 00:25:03 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:25:03 2024 ] Eval epoch: 41
[ Thu Oct 17 00:25:08 2024 ] Training epoch: 42
[ Thu Oct 17 00:25:56 2024 ] 	ACC:0.9402.
[ Thu Oct 17 00:25:56 2024 ] 	Mean training loss: 0.1992.
[ Thu Oct 17 00:25:56 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:25:56 2024 ] Eval epoch: 42
[ Thu Oct 17 00:26:01 2024 ] Training epoch: 43
[ Thu Oct 17 00:26:48 2024 ] 	ACC:0.9620.
[ Thu Oct 17 00:26:48 2024 ] 	Mean training loss: 0.1979.
[ Thu Oct 17 00:26:48 2024 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Oct 17 00:26:48 2024 ] Eval epoch: 43
[ Thu Oct 17 00:26:53 2024 ] Training epoch: 44
[ Thu Oct 17 00:27:41 2024 ] 	ACC:0.9728.
[ Thu Oct 17 00:27:41 2024 ] 	Mean training loss: 0.1972.
[ Thu Oct 17 00:27:41 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:27:41 2024 ] Eval epoch: 44
[ Thu Oct 17 00:27:46 2024 ] Training epoch: 45
[ Thu Oct 17 00:28:33 2024 ] 	ACC:0.9402.
[ Thu Oct 17 00:28:33 2024 ] 	Mean training loss: 0.1927.
[ Thu Oct 17 00:28:33 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:28:33 2024 ] Eval epoch: 45
[ Thu Oct 17 00:28:38 2024 ] Training epoch: 46
[ Thu Oct 17 00:29:26 2024 ] 	ACC:0.9620.
[ Thu Oct 17 00:29:26 2024 ] 	Mean training loss: 0.1833.
[ Thu Oct 17 00:29:26 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:29:26 2024 ] Eval epoch: 46
[ Thu Oct 17 00:29:31 2024 ] Training epoch: 47
[ Thu Oct 17 00:30:18 2024 ] 	ACC:0.9457.
[ Thu Oct 17 00:30:18 2024 ] 	Mean training loss: 0.1863.
[ Thu Oct 17 00:30:18 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:30:18 2024 ] Eval epoch: 47
[ Thu Oct 17 00:30:23 2024 ] Training epoch: 48
[ Thu Oct 17 00:31:11 2024 ] 	ACC:0.9402.
[ Thu Oct 17 00:31:11 2024 ] 	Mean training loss: 0.1843.
[ Thu Oct 17 00:31:11 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:31:11 2024 ] Eval epoch: 48
[ Thu Oct 17 00:31:16 2024 ] Training epoch: 49
[ Thu Oct 17 00:32:03 2024 ] 	ACC:0.9511.
[ Thu Oct 17 00:32:03 2024 ] 	Mean training loss: 0.1767.
[ Thu Oct 17 00:32:03 2024 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Oct 17 00:32:03 2024 ] Eval epoch: 49
[ Thu Oct 17 00:32:08 2024 ] Training epoch: 50
[ Thu Oct 17 00:32:56 2024 ] 	ACC:0.9620.
[ Thu Oct 17 00:32:56 2024 ] 	Mean training loss: 0.1756.
[ Thu Oct 17 00:32:56 2024 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Oct 17 00:32:56 2024 ] Eval epoch: 50
